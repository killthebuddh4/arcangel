# Overview of Parameters

Use claude-3.5-sonnet instead of GPT.

# Directional Change

GPT models get > 98% success, so there wasn't a ton of room to improve. But claude not only gets 100% success, but _I think_ it is significantly less dicey and faster (but also more expensive).

# Numbers

```
{
  "numExperiments": 55,
  "numSuccessful": 55,
  "numFailures": 0,
  "averageSuccessElapsedTime": 17748.254545454547,
  "averageProgress": 100,
  "averageFailureProgress": null,
  "averageNumMessages": 6.472727272727273,
  "averageSuccessMessages": 6.472727272727273,
  "averageFailureMessages": null,
  "numToolCallsByName": {},
  "averageToolCalls": 0,
  "averageFailureToolCalls": null,
  "averageSuccessToolCalls": 0,
  "model": "claude-3-5-sonnet-20240620"
}

```

# Failure Modes

None

# Notes

I think I'm going to switch to Claude as the primary model to work with. If I really struggle with something, or if I get to a point where I'm trying to optimize costs in some areas, I may use GPT-4o-mini.

# Next

Thinking...

Probably clean up the code to use anthropic.



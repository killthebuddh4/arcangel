# Overview of Parameters

NOTE: My previous run I accidentally failed to change the model which is why the results were identical :)

So the only thing I changed from the previous experiment was using `gpt-4o` instead of `gpt-4o-mini`. The model failed hard but one big reason is that for whatever reason `gpt-4o-mini` sets the cells to "red" while `gpt-4o` sets the cells to "0xFF0000", both options are fine but my code throws for the latter.

# Directional Change

# Numbers

```
{
  "numExperiments": 10,
  "numSuccessful": 0,
  "numFailures": 10,
  "averageProgress": 19.9,
  "averageFailureProgress": 19.9,
  "averageNumMessages": 37,
  "averageSuccessMessages": null,
  "averageFailureMessages": 37,
  "averageToolCalls": 14.5,
  "averageFailureToolCalls": 14.5,
  "averageSuccessToolCalls": null,
  "model": "gpt-4o"
}
```

# Failure Modes


# Next

- try bigger and smaller grids
- include an explicit diff that says progress (to avoid early exits)
- try non-vision models
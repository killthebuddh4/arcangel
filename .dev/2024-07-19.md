
SIDE NOTE: I want to be able to just record my audio/video at my desk and have a
daemon process that converts all of that into a lab notebook like this.

What are we doing? What's the plan?

Ultimately, we're making a system 2 compiler. But first let's try to get a
single ARC problem correct.

Before I even attempt to get one problem correct, I'm going to try to build up a
better intuition of what's required by writing some code to work with the
problems.

__ONE BIG NOTE: I'm going to try not to look at the test questions for as long
as possible because I want to have to keep my thinking as general as possible.__

---

So let's think about some of the stuff that the grids can represent. From what
I've seen their basically either:

- mechanical
- symmetric
- instructions

__MECH__

So the mechanical system examples show some kind of a physical law. From what
I've seen they are like physical laws of motion coupled with a behavior. I've
seen like

"go until you hit a wall then turn"

But I could also imagine something like 

"weave over and under these obstacles"

or something like that.

__SYMM__

these are basically just patterns to be completed, like maskings of some
symmetric thing.

__INSTR__

these are like where you can think of the input patterns as a kind of template
on what to do.


__These don't really get at it, they're not compressed enough__

Really they're all just encodings and decodings.

But some really are like physical and some really are mostly about pattern.

But what's the essential difference there?

Ok, so what are some keywords here:

- encoding decoding
- translation
- symmetryc
- motion
- expansion
- mutation
- transformation
- magnification
- extraction
- rotation
- dilation
- deformation

ok yeah so like some of the pairs are mappings

some of the pairs are like snippets

"What does this grid represent with respect to this other grid?"

And it could be categorically any one of the above keywords.

The core knowledge that Chollet talks about is more mechanical/physical but what
i've just listed is more operational or structural or, ooooh, maybe like
temporal.

We need to think about time and evolution also.

Also probably need to think about "repairing" pictures.

I've seen a few places mention that it's not just about "what's the simplest
answer" but that's still my intuition on what direction to go. Because there's
something about picking a pattern that another person would have picked that I
think is important. Like I do think there's a shared value system. Right like
imagine for some crazy reason that like every single example in a task happens
to look exactly like your name spelled in some alien language except for it's
missing like the last letter. You're going to think the pattern is your name. So
in some sense wwe have to consider patterns that we care about. So it's not
necessary the simplest but the simplest given the world we actually live in.
It's also the simplest given that a human can solve the problems. Like the
encoding really matters I think. Like different intelligences work with
different encodings.

__Ok, I know the first thing I'm going to try. The very first thing I'm going to
try is to apply "is there a rotation that generates each of the examples?". I'm
going to see if that hardcoded program solves any of the problems.__

So actually I'm not going to use rotations because rotations are approximate
enough that I believe they'd avoid them in the test examples. Instead I'll use a
different transform, let's think about this...

I'm going to think about this in terms of grid generation. What are the atomic
operations I could do on a grid?

# WRAPUP

So I also created an arcangel-ui next project because I realized it was a little bit too cumbersome to render gris to the terminal that were easy for me to grok. I also realized it might be more generally useufl to myself and others. I plan to publish a live version and share it.

Also, I decided to try out gpt-4o to see how well it could understand the grids, and it actually did a pretty decent job. I was going to work with a text model with a text representation of the grid but changed my mind for two reasons:

- the text models didn't seem to be able to process the grids all that well.
- many of the grids are very obviously (to my human eyes) physical/visual representations of light/occlusion/etc. It just seemed to me to make sense that a vision model might have a better latent understanding of the grids. but who knows.

But I made some progress, I can create an image from the data set and pass it to gpt-4o and gpt-4o does an ok job of telling me about the image (I chose a super simple one).
